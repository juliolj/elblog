---
title: "20 Preguntas y Respuestas para entrevistas de Machine Learning"
author: "Equipo LambdaOm"
output:
  pdf_document: default
  html_document: default
  word_document: default
header-includes:
- \usepackage{titling}
- \posttitle{\end{center}}
- \pretitle{\begin{center} \includegraphics[width=2in,height=2in]{C:/Users/DELL/Documents/NewDell/DocuLinux/LambdaOm/images/Logos/LambdaOm_brandX3.jpg}\LARGE\\}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción

Si quieres comenzar una carrera en el campo del *Machine Learning*, debes prepararte continuamente en aspectos técnicos, programación y conceptos básicos entre otras cosas. Como aspirante a profesional en éste campo, es fundamental que estés al tanto de cuáles son el tipo de preguntas que suelen realizar los encargados de las entrevistas técnicas durante los procesos de selección y contratación.

A continuación hemos reunido 20 preguntas y respuestas esenciales, que es muy probable que se te presenten durante una entrevista. Esta guía te ahorrará tiempo y agilizará tu camino de aprendizaje a la vez que adquieres una mayor confianza para enfrentar las entrevistas técnicas.

Uno de los objetivos primordiales al realizar esta guía es aportar contenido de calidad en material educativo en **idioma español**. No obstante, es de todos sabido que mucha de la terminología que se usa en este campo se encuentra en idioma inglés. Además, estamos convencidos de que cuando el aspirante se enfrenta en el mundo real a una entrevista técnica, es muy probable que se le presenten algunos términos y conceptos en idioma inglés. Debido a ello, en esta guía optamos por dejar alguna terminología y conceptos en idioma inglés, y en algunos casos, si lo consideramos informativo, presentamos algún concepto con su denominación en español, seguida de su denominación en inglés en paréntesis.

# Cómo utilizar esta guía.

Esta guía está diseñada para agilizar el estudio de algunos tópicos esenciales dentro del campo de *Machine learning,* y **la hemos concebido como un material de referencia rápido y como un punto de partida para un posterior proceso de investigación por parte del lector.** Así, nuestra principal recomendación para el uso de esta guía se puede resumir en lo siguiente:

**¡¡¡Poner mucha más atención a las preguntas que a las respuestas!!!**

Si bien hemos tomado todo el cuidado para que las respuestas aquí presentadas sean totalmente válidas, es posible complementarlas o aún considerar respuestas algo distintas considerando otros enfoques.

Estamos convencidos que las respuestas que aquí presentamos son lo suficientemente *estándar* como para funcionar bien en un amplio rango de tipos de entrevista y al menos pueden ser el punto de partida para una posterior elaboración por parte del aspirante si así le fuera requerido durante la entrevista.

El campo de *Machine Learning* es rico en perspectivas y complejidad, y eso da espacio a diferentes interpretaciones y grados de abstracción para atacar una determinada pregunta. Por lo anterior, **creemos que en general no es buena idea tratar de memorizar las respuestas aquí presentadas o tomarlas como las *respuestas definitivas* a las preguntas planteadas**. Siempre es importante estar al tanto del contexto, lo cual es particularmente cierto si estamos considerando el escenario de una entrevista técnica para competir por una posición en la industria.

Para abordar el estudio de esta guía de forma efectiva, nosotros sugerimos un *aprendizaje activo*: después de leer cada pregunta y su respectiva respuesta, hay que ir un paso más allá e investigar por cuenta propia de qué otras formas es posible complementar las respuestas aquí presentadas. Con ello, se obtendrá un mucho mayor beneficio en el aprendizaje y en la confianza adquirida para poder usar el conocimiento con mayor naturalidad y soltura.

Al final de cada respuesta hemos incluido algunos enlaces a fuentes en las que puedes encontrar información adicional respecto a cada pregunta. Puedes comenzar tu investigación visitando dichos sitios.

## ¡Y esto es sólo el comienzo!

Actualmente nos encontramos trabajando en una recopilación más extensa y detallada de preguntas técnicas para entrevista en el campo del *Machine Learning*. ¡Pronto recibirás noticias al respecto!

## ¡Colaboremos!

Finalmente, también invitamos a que compartas sugerencias, opiniones, correcciones, etc. Eso nos ayudará mucho a hacer mejoras en este y en próximos materiales y a seguir aprendiendo en este fascinante campo. Estamos abiertos y deseosos de explorar nuevas posibilidades de colaboración. Hagamos comunidad para fortalecernos profesionalmente.

¡Vamos a ello!

## 1. Explique los términos Inteligencia Artificial, *Machine Learning* (ML) y *Deep Learning* (DL).

Inteligencia Artificial es un campo muy amplio que explora la posibilidad de que un sistema informático o un conjunto de algoritmos expresen capacidades cognitivas e intelectuales que imiten a la inteligencia humana.

ML y DL son subcampos de la Inteligencia Artificial que se utilizan para entrenar a las computadoras para que aprendan y realicen tareas específicas sin una programación explícita.

ML se refiere a un enfoque de la inteligencia artificial donde las computadoras pueden aprender de los datos a través de un proceso de entrenamiento y mejorar su rendimiento en una tarea específica a medida que se les proporciona más información. Con el ML es posible extraer patrones y conocimientos de los datos mediante técnicas estadísticas y matemáticas. Sirve para tareas de clasificación, predicción, reconocimiento de patrones y toma de decisiones.

El DL es una rama del ML que se basa en redes neuronales artificiales inspiradas en el cerebro humano. En el DL, las redes neuronales se organizan en capas para aprender automáticamente representaciones de alto nivel de los datos. Con el DL es posible aprender características directamente de los datos de entrada, lo que lo hace especialmente adecuado para tareas de reconocimiento de imágenes, procesamiento del lenguaje natural y otras áreas donde la información se encuentra poco estructurada.

[**Liga**](https://www.ibm.com/blog/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks/)

## 2. ¿Cuáles son los diferentes tipos de modelos de Aprendizaje/Entrenamiento en ML?

Los algoritmos de ML se pueden clasificar principalmente según la disponibilidad o ausencia de las *variables objetivo*.

-   **Aprendizaje Supervisado** (Hay una variable objetivo): La máquina realiza un proceso de aprendizaje, utilizando **datos etiquetados**, donde el etiquetado se hace en función de la variable objetivo. El modelo es entrenado sobre un conjunto de datos existente (*training set*), antes de comenzar a tomar decisiones con datos nuevos.

    **Si la variable objetivo es continua**, se usan modelos de regresión lineal o polinomial.

    **Si la variable objetivo es categórica**, se usan modelos de regresión logística, *Naive* Bayes, KNN, SVM, Árboles de decisión, *Gradient Boosting*, *Random Forest*, etc.

-   **Aprendizaje No Supervisado** (No hay variable objetivo): La máquina es entrenada con datos no etiquetados y sin ninguna guía adecuada. Automáticamente infiere patrones y relaciones en los datos, las cuales generalmente dan lugar a la creación de *cluster*s de datos. El modelo aprende a través de los datos y deduce propiedades estructurales del conjunto de datos. Ejemplos: Análisis de Componentes Principales (PCA por sus siglas en inglés), Análisis de factores, Descomposición en Valores Singulares, etc.

-   **Aprendizaje reforzado** El modelo aprende a través de un método de prueba y error utilizando un sistema de *recompensa/penalización* para optimizar su respuesta en base a los datos existentes.

    [**Liga**](https://medium.com/soldai/tipos-de-aprendizaje-autom%C3%A1tico-6413e3c615e2)

## 3. ¿Cuál es la diferencia entre *Machine Learning* y *Deep Learning*?

Las diferencias clave son:

-   En el ML, se seleccionan manualmente las características, mientras que en DL la extracción de características es realizada automáticamente. 

-   En ML se requiere guiar a la máquina en cada una de las fases del proceso para que aprenda, a través del entrenamiento, a identificar lo que queremos de manera automática. Por otro lado, en el DL la máquina aprende por sí sola con cada nueva entrada de información que recibe.

[**Liga**](https://www.coursera.org/articles/ai-vs-deep-learning-vs-machine-learning-beginners-guide)

## 4. ¿Cuál es la principal diferencia clave entre modelos ML supervisados y no supervisados?

La técnica de aprendizaje supervisado necesita datos etiquetados para entrenar el modelo. Por ejemplo, para resolver un problema de clasificación, debe tener datos etiquetados (por ejemplo, como "éxito o fracaso") para entrenar el modelo y clasificar los datos en sus grupos etiquetados.

**El aprendizaje no supervisado no necesita ningún conjunto de datos etiquetados**. Esta es la principal diferencia clave entre el aprendizaje supervisado y el aprendizaje no supervisado.

[**Liga**](https://medium.com/soldai/tipos-de-aprendizaje-autom%C3%A1tico-6413e3c615e2)

## 5. ¿Cómo seleccionas variables importantes al trabajar con un conjunto de datos?

Existen varias formas de seleccionar variables relevantes dentro de un conjunto de datos:

-   Identificar y descartar variables que estén correlacionadas.

-   Usar conocimiento previo del dominio de aplicación.

-   Mediante alguna prueba de significancia estadística.

-   Regresión Lasso para selección de variables.

[**Liga**](https://es.wikipedia.org/wiki/Selecci%C3%B3n_de_variable)

## 6. ¿Cómo se diferencian entre sí la Covarianza y la Correlación?

-   Los coeficientes de correlación están estandarizados. Por lo tanto, una relación lineal positiva perfecta da como resultado un coeficiente de 1, mientras que una relación lineal negativa perfecta tiene un coeficiente de correlación de -1. La correlación mide tanto la fuerza como la dirección de la relación lineal entre dos variables y es independiente de su escala de valores.

-   Los valores de covarianza no están estandarizados. Por consiguiente, la covarianza puede ir desde infinito negativo hasta infinito positivo y es difícil determinar la fuerza de la relación entre las variables.

(<https://support.minitab.com/es-mx/minitab/21/help-and-how-to/statistics/basic-statistics/supporting-topics/correlation-and-covariance/what-is-covariance/#:~:text=El%20coeficiente%20de%20correlaci%C3%B3n%20es,siempre%20generar%C3%A1%20una%20correlaci%C3%B3n%20negativa.>)

## 7. ¿Cuál es la diferencia entre causalidad y correlación?

La causalidad se refiere a la situación en la que un factor X es responsable del cambio en otro factor Y, y podemos decir que X es una causa para Y.

La correlación solamente indica la relación existente entre dos factores, es decir, que bajo ciertas condiciones, estos factores tienden a variar conjuntamente.

**Es muy importante notar que a partir de una observación de correlación entre factores no es posible concluir relaciones de causalidad entre ellos.**

[**Liga**](https://exme.cochrane.org/blog/2022/08/30/correlacion-y-causalidad-una-guia-simple/)

## 8. Explica el *one-hot encoding* y el *label encoding*. ¿Cómo afectan éstos a la dimensionalidad?

*One-hot encoding* es la representación de variables categóricas como vectores binarios, con el fin de que ésta representación numérica sea más fácil de procesar para la máquina. Para entender cómo funciona, imaginemos que tenemos una variable categórica que puede tomar los valores "rojo", "verde" y "azul". Entonces, bajo el esquema de *one-hot encoding*, esta variable quedará codificada como un vector binario de 3 entradas, una para cada color. Así, si por ejemplo un objeto es de color rojo, su vector correspondiente tendrá un 1 en la columna correspondiente a rojo y 0 en las columnas restantes.

Evidentemente, una consecuencia de usar *one-hot encoding* es que la dimensionalidad de los datos de entrada aumenta.

El *label-encoding* es otra técnica para convertir variables categóricas en valores numéricos. A cada valor categórico se le asigna un número único. Esta técnica es útil cuando hay un orden en las categorías. Por ejemplo, a una variable categórica que puede tomar los valores "pequeño", "mediano" y "grande" se le puede asignar respectivamente los valores numéricos 1, 2 y 3. A diferencia del *one-hot encoding*, el *label-encoding* no afecta la dimensionalidad en los datos de entrada.

El *label-encoding* indtroduce necesariamente una jerarquía entre los valores de la variable categórica, por lo cual, si en la variable original no existe esta relación de jerarquía, es mejor optar por otro tipo de codificación, como lo es el *one-hot encoding*.

[**Liga**](https://www.kaggle.com/code/dansbecker/using-categorical-data-with-one-hot-encoding)

[**Liga**](https://www.mygreatlearning.com/blog/label-encoding-in-python/)

## 9. ¿En qué situaciones es relevante el uso de la regularización en modelos de ML?

Cuando el modelo comienza a ajustarse demasiado (*overfitting*) a los datos de entrenamiento, se hace necesaria la regularización. La regularización añade un término a la función de pérdida que penaliza el aumento de magnitud en los coeficientes estimados, con lo cual reduce la flexibilidad y desalienta un aprendizaje *excesivo* por parte del modelo respecto a los datos de entrenamento, disminuyendo así el riesgo de sobreajuste.

[**Liga**](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization?hl=es-419)

## 10. ¿Qué es *Bias*, *Variance* y a qué se refiere el *Bias-Variance Tradeoff*?

Ambos son errores en los algoritmos de aprendizaje automático. Cuando el algoritmo tiene una flexibilidad muy limitada para deducir la observación correcta del conjunto de datos, se produce el **sesgo o *bias*.** Por otro lado, la **varianza (*variance*)** ocurre cuando el modelo es extremadamente sensible a pequeñas fluctuaciones.

Si se agregan más funciones al construir un modelo, aumentará la complejidad del mismo, con lo que **disminuye el sesgo pero aumenta la varianza.** El ***Bias-Variance Tradeoff*** se refiere al hecho de que para mantener la cantidad óptima de error, es necesario lograr un balance adecuado entre el sesgo y la varianza en función de las necesidades de la aplicación.

El sesgo representa el error debido a suposiciones erróneas o demasiado simplistas en el algoritmo de aprendizaje. Esta suposición puede llevar a que el modelo no se ajuste bien a los datos, lo que dificulta tener una alta precisión predictiva y la generalización de las conclusiones al pasar del conjunto de entrenamiento al conjunto de prueba.

La varianza es un error debido a un exceso de complejidad en el algoritmo de aprendizaje. Esta puede ser la razón por la que el algoritmo es muy sensible a la variación en los datos de entrenamiento, lo que puede hacer que el modelo se ajuste excesivamente a los datos.

![](C:/Users/DELL/Documents/NewDell/DocuLinux/LambdaOm/images/bullseye.png)

[**https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html**](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote12.html){.uri}

## 11. ¿Qué se puede hacer si el conjunto de datos de entrenamiento presenta una alta varianza?

Para conjuntos de datos con alta varianza, podríamos usar el algoritmo de ***bagging***, también llamado ***bootstrap aggregating.*** Este algoritmo divide los datos en subgrupos por medio de muestreos aleatorios con reemplazo. Después se usa cada subgrupo como un set de entrenamiento para realizar la tarea (clasificación o regresión) y finalmente se combinan todos los resultados, por ejemplo a través de un proceso de votación, con lo cual se obtiene la decisión final del modelo.

[**Liga**](https://www.ibm.com/topics/bagging)

## 12. Se te proporciona un conjunto de datos sobre la detección de fraudes en servicios bancarios. Has construido un modelo clasificador, el cual obtiene una exactitud (accuracy) del 98,5 %. ¿Es este un buen modelo? En caso afirmativo, justifique. Si no, ¿qué puedes hacer al respecto?

A primera vista una exactitud de 98,5% podría considerarse más que aceptable. Sin embargo, el contexto es importante y aquí vemos que la aplicación se refiere a la detección de fraude. Generalmente, un conjunto de datos para detección de fraude no está balanceado, ya que la ocurrencia de fraude por lo general es un *evento raro*. Esto quiere decir que el conjunto de datos contendrá una gran cantidad de muestras negativas (no fraude) y algunas pocas positivas (hubo fraude).

En un conjunto de datos no balanceado, la exactitud no puede ser la medida del desempeño, ya que es posible obtener una alta exactitud aún cometiendo errores importantes de clasificación sobre la clase minoritaria, que es la que justamente nos interesa. Para evaluar el desempeño del modelo en caso de conjuntos de datos no balanceados, debemos utilizar la sensibilidad (tasa de verdaderos positivos) o la especificidad (tasa de verdaderos negativos) para determinar el desempeño del clasificador sobre instancias con etiquetado positivo e instancias con etiquetado negativo. Si el desempeño sobre instancias de clase minoritaria no es bueno, podríamos hacer lo siguiente:

-   Usar submuestreo o sobremuestreo para equilibrar los datos.

-   Cambiar el valor del umbral de predicción.

-   Asignar pesos a las etiquetas de modo que las etiquetas de las clases minoritarias obtengan pesos mayores.

-   Usar un algoritmo de detección de anomalías.

[**Liga**](https://www.kaggle.com/code/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets)

## 13. Explicar el manejo de valores faltantes o corruptos en el conjunto de datos dado.

Una manera fácil de manejar los valores perdidos o dañados es eliminar las filas o columnas correspondientes. Si hay demasiadas filas o columnas para descartar, consideramos reemplazar los valores faltantes o corruptos, mediante un proceso de imputación de valores. Existen métodos simples de imputación, como la moda o la media, métodos de imputación condicional mediante regresión y métodos avanzados de imputación como algoritmos de ML sobre datos completos para inferir los datos faltantes.

[**Liga**](https://www.kaggle.com/code/alexisbcook/missing-values)

## 14. ¿Qué es una Serie de Tiempo?

Una serie de tiempo es una secuencia de puntos de datos numéricos en orden sucesivo. Realiza un seguimiento del movimiento de los puntos de datos elegidos, durante un período de tiempo específico y registra los puntos de datos a intervalos regulares. Cada observación está asociada con una marca de tiempo específica, lo que permite analizar y modelar la evolución de los datos a lo largo de un período determinado.

[**Liga**](https://es.wikipedia.org/wiki/Serie_temporal)

## 15. ¿Qué es la transformación de Box-Cox?

La transformación de Box-Cox es una transformación de potencia que transforma las variables que siguen una distribución sesgada a variables con una distribución más simétrica y cercana a una distribución normal. Se aplica por lo general en modelos de regresión cuando los supuestos de varianza constante o de no linealidad no se cumplen. La transformación tiene un parámetro libre *lambda*, el cual cuando toma el valor de 0, implica que esta transformación es equivalente a la transformación logarítmica.

[**Liga**](https://es.wikipedia.org/wiki/Transformaci%C3%B3n_Box-Cox)

## 16. ¿Cuál es la diferencia entre descenso de gradiente estocástico y descenso de gradiente?

El descenso de gradiente estocástico (SGD por sus siglas en inglés) y el descenso de gradiente (GD) son algoritmos de optimización que se utilizan para encontrar el mínimo de la función de costo en el proceso de entrenamiento de un modelo de ML.

La diferencia es que en GD, se utilizan todos los datos de entrenamiento para actualizar el valor del gradiente en cada paso y recalcular el valor de los parámetros. En cambio, el SGD calcula el gradiente de la función de costo para un sólo ejemplo (o un conjunto reducido de ejemplos) seleccionado al azar en cada iteración y actualiza el valor de los parámetros utilizando el gradiente calculado con ése ejemplo específico.

[**Liga**](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)

## 17 ¿Cuál es el problema del gradiente explosivo al usar la técnica de propagación hacia atrás (*back propagation*)?

El problema de gradiente explosivo se refiere a la acumulación de grandes gradientes durante el proceso de entrenamiento de una red neuronal. Es un problema común en entrenamiento de redes neuronales que tienen varias capas (*redes profundas*). La acumulación del gradiente da como resultado grandes cambios en los pesos, volviendo inestable el proceso de aprendizaje. Los valores de los pesos pueden volverse tan grandes como para desbordarse y dar como resultado valores de NaN, haciendo que el proceso se detenga.

[**Liga**](https://www.youtube.com/watch?v=qhXZsFVxGKo)

## 18 ¿Puedes mencionar algunas ventajas y desventajas de los árboles de decisión?

**Ventajas:**

-   Son fáciles de interpretar (cuando no son demasiado grandes).

-   Funcionan bien en datos estructurados (tabulares)

-   Son capaces de modelar relaciones no lineales entre las variables predictoras y la variable objetivo.

-   Pueden manejar tipos de datos mixtos sin necesidad de codificaciones previas.

-   Eficiencia en tiempo de entrenamiento y predicción.

-   Son robustos frente a valores atípicos.

**Desventajas:**

-   Son propensos al sobreajuste.

-   Alta sensibilidad a los cambios en los datos de entrenamiento.

-   Sesgo hacia variables categóricas con un mayor número de niveles.

-   Dificultad para capturar relaciones complejas que no son de naturaleza jerárquica.

-   Su capacidad es limitada en tareas de regresión.

[**Liga**](https://en.wikipedia.org/wiki/Decision_tree_learning)

## 19. Explique las diferencias entre los modelos *Random Forest* y *Gradient Boosting*.

-   *Random Forest* (RF) construye árboles de decisión independientes de forma paralela mientras que *Gradient Boosting* (GB) lo hace de manera secuencial para mejorar el rendimiento del modelo.

-   RF utiliza el muestreo por bootstrapping mientras que GB usa descenso de gradiente.

-   En RF las decisiones finales se obtienen por un sistema de mayoría de votos, mientras que en GB las predicciones se obtienen al sumar la contribución ponderada de cada árbol.

[**Liga**](https://stats.stackexchange.com/questions/173390/gradient-boosting-tree-vs-random-forest)

## 20. ¿Qué es una matriz de confusión y para qué se utiliza?

La matriz de confusión (también llamada matriz de error) es un resumen en forma tabular de las predicciones de un modelo de clasificación, donde las filas representan las clases *reales* o verdaderas y las columnas representan las predicciones hechas por el modelo. . El número de predicciones correctas e incorrectas se resume con valores de conteo y se desglosa por cada etiqueta de clase. Nos da información sobre los errores cometidos por el clasificador y también los tipos de errores cometidos.

Se utiliza para ilustrar el rendimiento de un clasificador en un conjunto de datos de prueba para los cuales los valores verdaderos son conocidos. A partir de una matriz de confusión se pueden obtener varias métricas de evaluación como Verdaderos Positivos, Verdaderos Negativos, Falsos Positivos y Falsos Negativos.

[**Liga**](https://es.wikipedia.org/wiki/Matriz_de_confusi%C3%B3n)
